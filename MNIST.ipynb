{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e74633fa-bd6d-49b7-ba58-c3e6e142c3a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15f16a9d-6cbe-4bb9-8eaf-50265b814667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pre = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "train_mean = train_pre.data.float().mean() / 255 \n",
    "train_std = train_pre.data.float().std() / 255\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(train_mean,train_std)])\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "428cdd03-2b8b-4040-84f3-37df903b2743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.fc1(x)\n",
    "        return nn.functional.softmax(x)\n",
    "    \n",
    "net = ConvNet() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "580f9ef7-eac3-4ff8-adae-6d0f13262ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/07/65yfr7y95sd5nhnx51849p580000gn/T/ipykernel_32541/471972347.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return nn.functional.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.059\n",
      "[2,   100] loss: 1.657\n",
      "[3,   100] loss: 1.570\n",
      "[4,   100] loss: 1.547\n",
      "[5,   100] loss: 1.532\n",
      "[6,   100] loss: 1.523\n",
      "[7,   100] loss: 1.516\n",
      "[8,   100] loss: 1.510\n",
      "[9,   100] loss: 1.505\n",
      "[10,   100] loss: 1.501\n",
      "[11,   100] loss: 1.498\n",
      "[12,   100] loss: 1.495\n",
      "[13,   100] loss: 1.493\n",
      "[14,   100] loss: 1.491\n",
      "[15,   100] loss: 1.489\n",
      "[16,   100] loss: 1.488\n",
      "[17,   100] loss: 1.486\n",
      "[18,   100] loss: 1.485\n",
      "[19,   100] loss: 1.484\n",
      "[20,   100] loss: 1.484\n",
      "[21,   100] loss: 1.483\n",
      "[22,   100] loss: 1.481\n",
      "[23,   100] loss: 1.482\n",
      "[24,   100] loss: 1.480\n",
      "[25,   100] loss: 1.480\n",
      "[26,   100] loss: 1.479\n",
      "[27,   100] loss: 1.479\n",
      "[28,   100] loss: 1.478\n",
      "[29,   100] loss: 1.477\n",
      "[30,   100] loss: 1.477\n",
      "[31,   100] loss: 1.477\n",
      "[32,   100] loss: 1.476\n",
      "[33,   100] loss: 1.476\n",
      "[34,   100] loss: 1.476\n",
      "[35,   100] loss: 1.476\n",
      "[36,   100] loss: 1.475\n",
      "[37,   100] loss: 1.475\n",
      "[38,   100] loss: 1.474\n",
      "[39,   100] loss: 1.474\n",
      "[40,   100] loss: 1.474\n",
      "[41,   100] loss: 1.474\n",
      "[42,   100] loss: 1.473\n",
      "[43,   100] loss: 1.473\n",
      "[44,   100] loss: 1.473\n",
      "[45,   100] loss: 1.473\n",
      "[46,   100] loss: 1.472\n",
      "[47,   100] loss: 1.472\n",
      "[48,   100] loss: 1.472\n",
      "[49,   100] loss: 1.472\n",
      "[50,   100] loss: 1.472\n",
      "[51,   100] loss: 1.472\n",
      "[52,   100] loss: 1.471\n",
      "[53,   100] loss: 1.471\n",
      "[54,   100] loss: 1.471\n",
      "[55,   100] loss: 1.471\n",
      "[56,   100] loss: 1.471\n",
      "[57,   100] loss: 1.470\n",
      "[58,   100] loss: 1.470\n",
      "[59,   100] loss: 1.470\n",
      "[60,   100] loss: 1.470\n",
      "[61,   100] loss: 1.470\n",
      "[62,   100] loss: 1.470\n",
      "[63,   100] loss: 1.470\n",
      "[64,   100] loss: 1.470\n",
      "[65,   100] loss: 1.470\n",
      "[66,   100] loss: 1.469\n",
      "[67,   100] loss: 1.469\n",
      "[68,   100] loss: 1.469\n",
      "[69,   100] loss: 1.469\n",
      "[70,   100] loss: 1.469\n",
      "[71,   100] loss: 1.469\n",
      "[72,   100] loss: 1.469\n",
      "[73,   100] loss: 1.468\n",
      "[74,   100] loss: 1.468\n",
      "[75,   100] loss: 1.468\n",
      "[76,   100] loss: 1.469\n",
      "[77,   100] loss: 1.468\n",
      "[78,   100] loss: 1.468\n",
      "[79,   100] loss: 1.468\n",
      "[80,   100] loss: 1.468\n",
      "[81,   100] loss: 1.468\n",
      "[82,   100] loss: 1.468\n",
      "[83,   100] loss: 1.468\n",
      "[84,   100] loss: 1.468\n",
      "[85,   100] loss: 1.468\n",
      "[86,   100] loss: 1.468\n",
      "[87,   100] loss: 1.468\n",
      "[88,   100] loss: 1.467\n",
      "[89,   100] loss: 1.467\n",
      "[90,   100] loss: 1.467\n",
      "[91,   100] loss: 1.467\n",
      "[92,   100] loss: 1.468\n",
      "[93,   100] loss: 1.467\n",
      "[94,   100] loss: 1.467\n",
      "[95,   100] loss: 1.467\n",
      "[96,   100] loss: 1.467\n",
      "[97,   100] loss: 1.467\n",
      "[98,   100] loss: 1.467\n",
      "[99,   100] loss: 1.467\n",
      "[100,   100] loss: 1.467\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 5\n",
    "print_every = 100\n",
    "\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f82dafa0-f5c2-4e75-b506-d4fc4b15c560",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/07/65yfr7y95sd5nhnx51849p580000gn/T/ipykernel_32541/471972347.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return nn.functional.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.74\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
